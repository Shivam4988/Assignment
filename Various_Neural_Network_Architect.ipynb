{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN/xe69PgHqq96uBZYRl5Od",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shivam4988/Assignment/blob/main/Various_Neural_Network_Architect.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Describe the basic structure of a Feedforward Neural Network (FNN). What is the purpose of the activation function?\n",
        "A Feedforward Neural Network (FNN) consists of an input layer, one or more hidden layers, and an output layer. Data flows unidirectionally from input to output without cycles. Each neuron in a layer is fully connected to neurons in the subsequent layer via weights and biases. The activation function (e.g., ReLU, sigmoid, tanh) introduces non-linearity, enabling the network to model complex patterns beyond linear relationships. Without activation functions, the network would collapse into a linear regression model.\n",
        "\n"
      ],
      "metadata": {
        "id": "8_rZV_AH_NxH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Explain the role of convolutional layers in a CNN. Why are pooling layers commonly used, and what do they achieve?\n",
        "Convolutional layers in a CNN apply learnable filters (kernels) to extract spatial features (e.g., edges, textures) from input data. These filters slide over the input, performing element-wise multiplication and summation to produce feature maps. Pooling layers (e.g., max pooling, average pooling) downsample feature maps, reducing spatial dimensions and computational complexity. They also introduce translation invariance, making the network robust to small shifts in input features and helping prevent overfitting."
      ],
      "metadata": {
        "id": "4EzrWLT5_RZx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. What is the key characteristic that differentiates Recurrent Neural Networks (RNNs) from other neural networks? How does an RNN handle sequential data?\n",
        "RNNs are distinguished by their internal memory, enabled by loops that allow information persistence across time steps. They process sequential data (e.g., text, time series) by maintaining a hidden state that captures context from previous inputs. At each step, the hidden state is updated and passed forward, enabling the network to leverage temporal dependencies. However, standard RNNs struggle with long-term dependencies due to vanishing/exploding gradients."
      ],
      "metadata": {
        "id": "EPV0ZiIY_VRL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Discuss the components of a Long Short-Term Memory (LSTM) network. How does it address the vanishing gradient problem?\n",
        "An LSTM consists of a cell state and three gates:\n",
        "\n",
        "Forget gate: Decides what information to discard from the cell state.\n",
        "\n",
        "Input gate: Updates the cell state with new relevant information.\n",
        "\n",
        "Output gate: Controls what information is outputted from the cell state.\n",
        "\n",
        "The cell state acts as a \"memory highway,\" allowing gradients to flow unchanged over long sequences. By regulating information flow through gating mechanisms, LSTMs mitigate the vanishing gradient problem common in vanilla RNNs, enabling effective learning of long-term dependencies."
      ],
      "metadata": {
        "id": "XU8-nT08_ZMK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Describe the roles of the generator and discriminator in a Generative Adversarial Network (GAN). What is the training objective for each?\n",
        "\n",
        "Generator: Creates synthetic data (e.g., images) to mimic the real data distribution. Its objective is to fool the discriminator into classifying fake data as real.\n",
        "\n",
        "Discriminator: Distinguishes between real and generated data. Its objective is to correctly classify inputs as real or fake.\n",
        "\n",
        "Training is adversarial: the generator minimizes the discriminatorâ€™s accuracy (via loss functions like binary cross-entropy), while the discriminator maximizes its own accuracy. This minimax game drives the generator to produce increasingly realistic data until the discriminator cannot differentiate between real and fake samples.\n",
        "\n"
      ],
      "metadata": {
        "id": "qrxDkuRX_gop"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QRcyI64N_Jbj"
      },
      "outputs": [],
      "source": []
    }
  ]
}